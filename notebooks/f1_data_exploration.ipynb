{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35811a6e",
   "metadata": {},
   "source": [
    "# F1 Lakehouse - Data Exploration and AI Insight Notebook\n",
    "\n",
    "Use this notebook to inspect the DuckDB warehouse that backs the lakehouse, spot data-quality issues, and generate ideas that make downstream models (dbt, Streamlit, or ML) more accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9120fec",
   "metadata": {},
   "source": [
    "## How to use this notebook\n",
    "\n",
    "1. Mount the external SSD so `/Volumes/SAMSUNG/f1-lakehouse-data` is available and run `scripts/init_external.sh` at least once.\n",
    "2. Load the `.env` file in your shell (`export $(grep -v '^#' .env | xargs)` in zsh) so `EXTERNAL_DATA_ROOT` and `F1_WAREHOUSE` are defined.\n",
    "3. Execute the dependency cell below the first time you open this notebook in a new environment.\n",
    "4. Optional but recommended: set `OPENAI_API_KEY` (and `OPENAI_MODEL` if you want to override the default) before running the ChatGPT helper cell.\n",
    "\n",
    "The notebook resolves the DuckDB path automatically by checking `F1_WAREHOUSE`, the `/opt/data` mount inside containers, and the host-side SSD path. All cells assume sequential execution so run them from top to bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q duckdb pandas plotly openai python-dotenv \"nbformat>=5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cca2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "\n",
    "def ns_to_seconds(series: pd.Series) -> pd.Series:\n",
    "    # Convert integer nanosecond values to floating-point seconds.\n",
    "    return pd.to_numeric(series, errors=\"coerce\") / 1e9\n",
    "\n",
    "\n",
    "def ns_to_pretty(series: pd.Series) -> pd.Series:\n",
    "    # Render nanosecond durations as mm:ss.mmm strings.\n",
    "    td = pd.to_timedelta(ns_to_seconds(series), unit=\"s\")\n",
    "    return td.apply(\n",
    "        lambda x: f\"{int(x.total_seconds() // 60):02d}:{int(x.total_seconds() % 60):02d}.{int(x.microseconds / 1000):03d}\"\n",
    "        if pd.notna(x)\n",
    "        else None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTERNAL_ROOT = Path(os.environ.get(\"EXTERNAL_DATA_ROOT\", \"/Volumes/SAMSUNG/f1-lakehouse-data\"))\n",
    "WAREHOUSE_ENV = Path(os.environ.get(\"F1_WAREHOUSE\", \"/opt/data/warehouse/f1.duckdb\"))\n",
    "\n",
    "candidate_paths = []\n",
    "for path in (\n",
    "    WAREHOUSE_ENV,\n",
    "    Path(str(WAREHOUSE_ENV).replace(\"/opt/data\", str(EXTERNAL_ROOT)))\n",
    "    if str(WAREHOUSE_ENV).startswith(\"/opt/data\")\n",
    "    else None,\n",
    "    EXTERNAL_ROOT / \"warehouse\" / \"f1.duckdb\",\n",
    "    Path.cwd() / \"warehouse\" / \"f1.duckdb\",\n",
    "):\n",
    "    if path and path not in candidate_paths:\n",
    "        candidate_paths.append(path)\n",
    "\n",
    "WAREHOUSE_PATH = next((p for p in candidate_paths if p.exists()), None)\n",
    "if WAREHOUSE_PATH is None:\n",
    "    raise FileNotFoundError(f\"Could not find DuckDB warehouse in any of: {candidate_paths}\")\n",
    "\n",
    "print(f\"Using DuckDB warehouse at {WAREHOUSE_PATH}\")\n",
    "con = duckdb.connect(str(WAREHOUSE_PATH), read_only=True)\n",
    "\n",
    "\n",
    "def resolve_schema(connection: duckdb.DuckDBPyConnection, base_schema: str, table_name: Optional[str] = None) -> str:\n",
    "    candidates = [f\"main_{base_schema}\", base_schema]\n",
    "    for schema in candidates:\n",
    "        exists = connection.execute(\n",
    "            \"SELECT 1 FROM information_schema.schemata WHERE schema_name = ? LIMIT 1\",\n",
    "            [schema],\n",
    "        ).fetchone()\n",
    "        if not exists:\n",
    "            continue\n",
    "        if table_name:\n",
    "            table_exists = connection.execute(\n",
    "                \"SELECT 1 FROM information_schema.tables WHERE table_schema = ? AND table_name = ? LIMIT 1\",\n",
    "                [schema, table_name],\n",
    "            ).fetchone()\n",
    "            if not table_exists:\n",
    "                continue\n",
    "        return schema\n",
    "    raise ValueError(f\"Could not find schema {base_schema} (table {table_name!r}).\")\n",
    "\n",
    "\n",
    "def run_df(query: str, params: Optional[dict] = None) -> pd.DataFrame:\n",
    "    return con.execute(query, params or {}).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3372edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_schema = resolve_schema(con, \"silver\", \"laps\")\n",
    "gold_schema = resolve_schema(con, \"gold\", \"driver_session_summary\")\n",
    "print(f\"Resolved schemas -> silver: {silver_schema}, gold: {gold_schema}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feed436",
   "metadata": {},
   "source": [
    "### Table inventory\n",
    "Inspect how many rows exist per modeled table so you know what is available for exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = run_df(f\"\"\"\n",
    "SELECT table_schema, table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema IN ('{silver_schema}', '{gold_schema}')\n",
    "ORDER BY table_schema, table_name\n",
    "\"\"\")\n",
    "\n",
    "row_counts = []\n",
    "for schema, table in table_df[[\"table_schema\", \"table_name\"]].itertuples(index=False):\n",
    "    row_counts.append(con.execute(f\"SELECT COUNT(*) FROM {schema}.{table}\").fetchone()[0])\n",
    "\n",
    "table_df[\"row_count\"] = row_counts\n",
    "table_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014897af",
   "metadata": {},
   "source": [
    "### Season coverage and KPIs\n",
    "Identify which seasons and sessions are loaded plus high-level lap counts, driver coverage, and team coverage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb82206",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_counts = run_df(f\"\"\"\n",
    "SELECT\n",
    "  season,\n",
    "  session_code,\n",
    "  COUNT(*)            AS lap_count,\n",
    "  COUNT(DISTINCT driver) AS drivers,\n",
    "  COUNT(DISTINCT team)   AS teams\n",
    "FROM {silver_schema}.laps\n",
    "GROUP BY 1, 2\n",
    "ORDER BY season DESC, session_code\n",
    "\"\"\")\n",
    "\n",
    "if season_counts.empty:\n",
    "    raise RuntimeError(\"No lap data found. Run ingestion + dbt before using this notebook.\")\n",
    "\n",
    "latest_season = int(season_counts[\"season\"].max())\n",
    "latest_round_df = run_df(\n",
    "    f\"\"\"SELECT MAX(round) AS round FROM {silver_schema}.laps WHERE season = $season\"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "latest_round = int(latest_round_df.iloc[0][\"round\"])\n",
    "print(f\"Latest season detected: {latest_season} (round {latest_round})\")\n",
    "season_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb82bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    season_counts,\n",
    "    x=\"session_code\",\n",
    "    y=\"lap_count\",\n",
    "    color=season_counts[\"season\"].astype(str),\n",
    "    barmode=\"group\",\n",
    "    title=\"Lap counts by session\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Session\", yaxis_title=\"Lap count\", legend_title=\"Season\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3ee1d",
   "metadata": {},
   "source": [
    "### Lap-level preview (latest season/round)\n",
    "Review a thin slice of lap telemetry to understand which columns need cleaning or feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_preview = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      season, round, grand_prix, session_code,\n",
    "      driver, drivernumber, team,\n",
    "      lapnumber, stint,\n",
    "      laptime, sector1time, sector2time, sector3time,\n",
    "      pitouttime, pitintime,\n",
    "      compound, tyrelife, freshtyre, trackstatus\n",
    "    FROM {silver_schema}.laps\n",
    "    WHERE season = $season AND round = $round\n",
    "    ORDER BY session_code, driver, lapnumber\n",
    "    LIMIT 25\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season, \"round\": latest_round},\n",
    ")\n",
    "\n",
    "for col in [\"laptime\", \"sector1time\", \"sector2time\", \"sector3time\"]:\n",
    "    if col in laps_preview.columns:\n",
    "        laps_preview[f\"{col}_sec\"] = ns_to_seconds(laps_preview[col]).round(3)\n",
    "\n",
    "laps_preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343a489",
   "metadata": {},
   "source": [
    "### Missing values and potential data-cleaning targets\n",
    "Measure column-level null percentages for the latest season to prioritize cleaning work (e.g., missing compounds or lap times).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c628cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_latest = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {silver_schema}.laps\n",
    "    WHERE season = $season\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "\n",
    "missing = laps_latest.isna().mean().sort_values(ascending=False) * 100\n",
    "missing = missing[missing > 0]\n",
    "missing_df = missing.round(2).reset_index()\n",
    "missing_df.columns = [\"column\", \"missing_pct\"]\n",
    "missing_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438510ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    missing_df.head(20),\n",
    "    x=\"column\",\n",
    "    y=\"missing_pct\",\n",
    "    title=f\"Top 20 columns by missing percentage (season {latest_season})\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Column\", yaxis_title=\"Percent missing\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd534d",
   "metadata": {},
   "source": [
    "### Driver/number consistency checks\n",
    "Spot drivers that map to multiple numbers or teams within the same season (possible data-quality issues).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_aliases = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      driver,\n",
    "      COUNT(DISTINCT drivernumber) AS distinct_numbers,\n",
    "      COUNT(DISTINCT team)         AS distinct_teams\n",
    "    FROM {silver_schema}.laps\n",
    "    WHERE season = $season\n",
    "    GROUP BY driver\n",
    "    HAVING COUNT(DISTINCT drivernumber) > 1\n",
    "       OR COUNT(DISTINCT team) > 1\n",
    "    ORDER BY distinct_numbers DESC, distinct_teams DESC\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "driver_aliases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea36f9",
   "metadata": {},
   "source": [
    "### Lap-time distribution and outliers\n",
    "Convert nanoseconds to seconds and visualize the lap-time spread per session to pinpoint outliers or sessions that need trimming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b91d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pacedata = laps_latest.dropna(subset=[\"laptime\"]).copy()\n",
    "pacedata[\"lap_seconds\"] = ns_to_seconds(pacedata[\"laptime\"])\n",
    "\n",
    "fig = px.histogram(\n",
    "    pacedata,\n",
    "    x=\"lap_seconds\",\n",
    "    color=\"session_code\",\n",
    "    nbins=60,\n",
    "    opacity=0.75,\n",
    "    title=f\"Lap-time distribution (season {latest_season})\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Lap time (seconds)\", yaxis_title=\"Lap count\")\n",
    "fig.show()\n",
    "\n",
    "pace_stats = pacedata.groupby(\"session_code\")[\"lap_seconds\"].agg([\"count\", \"min\", \"median\", \"max\"]).round(3)\n",
    "pace_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c9379",
   "metadata": {},
   "source": [
    "### Tyre compound mix\n",
    "Check tyre usage counts to understand whether additional balancing or filtering is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_mix = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT compound, COUNT(*) AS laps\n",
    "    FROM {silver_schema}.laps\n",
    "    WHERE season = $season AND compound IS NOT NULL\n",
    "    GROUP BY compound\n",
    "    ORDER BY laps DESC\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "compound_mix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1075ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    compound_mix,\n",
    "    x=\"compound\",\n",
    "    y=\"laps\",\n",
    "    title=f\"Tyre compound usage (season {latest_season})\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Compound\", yaxis_title=\"Lap count\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2655551",
   "metadata": {},
   "source": [
    "### Weather context vs. pace\n",
    "Aggregate weather signals per session and compare them to driver pace so you can spot environmental drivers of variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_agg = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      season,\n",
    "      round,\n",
    "      session_code,\n",
    "      AVG(tracktemp)  AS avg_track_temp,\n",
    "      AVG(airtemp)    AS avg_air_temp,\n",
    "      AVG(windspeed)  AS avg_wind_speed,\n",
    "      MAX(CASE WHEN rainfall THEN 1 ELSE 0 END) AS had_rain\n",
    "    FROM {silver_schema}.weather\n",
    "    GROUP BY 1, 2, 3\n",
    "    ORDER BY season DESC, round DESC, session_code\n",
    "    \"\"\"\n",
    ")\n",
    "weather_agg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be491e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pace_vs_weather = run_df(\n",
    "    f\"\"\"\n",
    "    WITH pace AS (\n",
    "      SELECT\n",
    "        season,\n",
    "        round,\n",
    "        session_code,\n",
    "        driver,\n",
    "        team,\n",
    "        MIN(laptime) AS best_lap_ns\n",
    "      FROM {silver_schema}.laps\n",
    "      WHERE season = $season\n",
    "      GROUP BY 1, 2, 3, 4, 5\n",
    "    )\n",
    "    SELECT\n",
    "      p.driver,\n",
    "      p.team,\n",
    "      p.session_code,\n",
    "      p.best_lap_ns,\n",
    "      w.avg_track_temp,\n",
    "      w.avg_air_temp,\n",
    "      w.had_rain\n",
    "    FROM pace p\n",
    "    LEFT JOIN weather_agg w\n",
    "      ON p.season = w.season\n",
    "     AND p.round = w.round\n",
    "     AND p.session_code = w.session_code\n",
    "    WHERE p.session_code = 'R'\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "\n",
    "pace_vs_weather[\"best_lap_seconds\"] = ns_to_seconds(pace_vs_weather[\"best_lap_ns\"])\n",
    "fig = px.scatter(\n",
    "    pace_vs_weather,\n",
    "    x=\"avg_track_temp\",\n",
    "    y=\"best_lap_seconds\",\n",
    "    color=\"team\",\n",
    "    hover_name=\"driver\",\n",
    "    title=\"Best race lap vs. average track temperature\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Avg track temp (C)\", yaxis_title=\"Best lap (s)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b12325",
   "metadata": {},
   "source": [
    "### Silver results snapshot\n",
    "Inspect broadcast-facing result attributes (positions, grid, points, status) to compare against lap-derived metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_snapshot = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      season,\n",
    "      round,\n",
    "      session_code,\n",
    "      broadcastname AS driver_name,\n",
    "      teamname,\n",
    "      position,\n",
    "      classifiedposition,\n",
    "      gridposition,\n",
    "      status,\n",
    "      points\n",
    "    FROM {silver_schema}.results\n",
    "    WHERE season = $season\n",
    "    ORDER BY round DESC, session_code DESC, position\n",
    "    LIMIT 40\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "results_snapshot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79669685",
   "metadata": {},
   "source": [
    "### Gold mart: driver_session_summary\n",
    "Use the curated gold table to connect lap behavior to business-ready metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da79dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_summary = run_df(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      season,\n",
    "      round,\n",
    "      grand_prix,\n",
    "      session_code,\n",
    "      driver,\n",
    "      team,\n",
    "      laps_total,\n",
    "      laps_on_track,\n",
    "      pitstops,\n",
    "      best_lap_time,\n",
    "      personal_best_laps\n",
    "    FROM {gold_schema}.driver_session_summary\n",
    "    WHERE season = $season\n",
    "    ORDER BY round DESC, session_code, best_lap_time\n",
    "    \"\"\",\n",
    "    {\"season\": latest_season},\n",
    ")\n",
    "\n",
    "driver_summary[\"best_lap_seconds\"] = ns_to_seconds(driver_summary[\"best_lap_time\"])\n",
    "driver_summary.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    driver_summary,\n",
    "    x=\"laps_on_track\",\n",
    "    y=\"best_lap_seconds\",\n",
    "    color=\"team\",\n",
    "    hover_name=\"driver\",\n",
    "    facet_col=\"session_code\",\n",
    "    title=f\"Best lap vs. track time (season {latest_season})\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Laps on track\", yaxis_title=\"Best lap (s)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371956e",
   "metadata": {},
   "source": [
    "### ChatGPT-powered insights (optional)\n",
    "Call OpenAI's API to summarize findings or suggest cleaning actions using any DataFrame from above. Requires `OPENAI_API_KEY` to be set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    OpenAI = None\n",
    "\n",
    "\n",
    "def summarize_with_chatgpt(df: pd.DataFrame, question: str, sample_rows: int = 40, model: Optional[str] = None) -> str:\n",
    "    \"\"\"Send a compact CSV sample plus a question to ChatGPT and return the response.\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty. Provide rows before calling the model.\")\n",
    "    if OpenAI is None:\n",
    "        raise ImportError(\"openai package is missing. Re-run the %pip install cell.\")\n",
    "\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise EnvironmentError(\"OPENAI_API_KEY is not set in the environment.\")\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    model_name = model or os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "    sample = df.head(sample_rows)\n",
    "    csv_payload = sample.to_csv(index=False)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a senior analytics engineer. \"\n",
    "                \"Read the CSV rows, describe notable patterns or anomalies, and suggest concrete data cleaning or modeling actions.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Question: {question}\\n\\nCSV sample:\\n{csv_payload}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=400,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_input = driver_summary.loc[driver_summary[\"session_code\"] == \"R\", [\n",
    "    \"driver\",\n",
    "    \"team\",\n",
    "    \"laps_on_track\",\n",
    "    \"pitstops\",\n",
    "    \"best_lap_seconds\",\n",
    "    \"personal_best_laps\",\n",
    "]].copy()\n",
    "ai_question = f\"Where should we focus cleaning or feature engineering to improve race-pace insights for season {latest_season}?\"\n",
    "\n",
    "try:\n",
    "    ai_response = summarize_with_chatgpt(ai_input, question=ai_question, sample_rows=25)\n",
    "    print(ai_response)\n",
    "except Exception as exc:\n",
    "    print(f\"AI insight unavailable: {exc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
